{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "2.19. Writing a Simple Recursive Descent Parser"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Problem\n",
      "You need to parse text according to a set of grammar rules and perform actions or build\n",
      "an abstract syntax tree representing the input. The grammar is small, so you\u2019d prefer to\n",
      "just write the parser yourself as opposed to using some kind of framework.\n",
      "\n",
      "# Solution\n",
      "In this problem, we\u2019re focused on the problem of parsing text according to a particular\n",
      "grammar. In order to do this, you should probably start by having a formal specification\n",
      "of the grammar in the form of a BNF or EBNF. For example, a grammar for simple\n",
      "arithmetic expressions might look like this:\n",
      "```\n",
      "expr ::= expr + term\n",
      "     | expr - term\n",
      "     | term\n",
      "\n",
      "term ::= term * factor\n",
      "     | term / factor\n",
      "     | factor\n",
      "\n",
      "factor ::= ( expr )\n",
      "       | NUM\n",
      "```\n",
      "Or, alternatively, in EBNF form:\n",
      "```\n",
      "expr ::= term { (+|-) term }*\n",
      "\n",
      "term ::= factor { (*|/) factor }*\n",
      "\n",
      "factor ::= ( expr )\n",
      "       | NUM\n",
      "```\n",
      "In an EBNF, parts of a rule enclosed in `{ ... }*` are optional. The `*` means zero or more\n",
      "repetitions (the same meaning as in a regular expression).\n",
      "\n",
      "Now, if you\u2019re not familiar with the mechanics of working with a BNF, think of it as a\n",
      "specification of substitution or replacement rules where symbols on the left side can be\n",
      "replaced by the symbols on the right (or vice versa). Generally, what happens during\n",
      "parsing is that you try to match the input text to the grammar by making various substitutions \n",
      "and expansions using the BNF. To illustrate, suppose you are parsing an expression \n",
      "such as `3 + 4 * 5`. This expression would first need to be broken down into\n",
      "a token stream, using the techniques described in Recipe 2.18. The result might be a\n",
      "sequence of tokens like this:\n",
      "```\n",
      "NUM + NUM * NUM\n",
      "```\n",
      "From there, parsing involves trying to match the grammar to input tokens by making\n",
      "substitutions:\n",
      "```\n",
      "expr\n",
      "expr ::= term { (+|-) term }*\n",
      "expr ::= factor { (*|/) factor }* { (+|-) term }*\n",
      "expr ::= NUM { (*|/) factor }* { (+|-) term }*\n",
      "expr ::= NUM { (+|-) term }*\n",
      "expr ::= NUM + term { (+|-) term }*\n",
      "expr ::= NUM + factor { (*|/) factor }* { (+|-) term }*\n",
      "expr ::= NUM + NUM { (*|/) factor}* { (+|-) term }*\n",
      "expr ::= NUM + NUM * factor { (*|/) factor }* { (+|-) term }*\n",
      "expr ::= NUM + NUM * NUM { (*|/) factor }* { (+|-) term }*\n",
      "expr ::= NUM + NUM * NUM { (+|-) term }*\n",
      "expr ::= NUM + NUM * NUM\n",
      "```\n",
      "\n",
      "Following all of the substitution steps takes a bit of coffee, but they\u2019re driven by looking\n",
      "at the input and trying to match it to grammar rules. The first input token is a `NUM`, so\n",
      "substitutions first focus on matching that part. Once matched, attention moves to the\n",
      "next token of `+` and so on. Certain parts of the righthand side \n",
      "(e.g., `{ (*/) factor }*`) disappear when it\u2019s determined that they can\u2019t match the next token. In a suc\u2010\n",
      "cessful parse, the entire righthand side is expanded completely to match the input token\n",
      "stream.\n",
      "\n",
      "With all of the preceding background in place, here is a simple recipe that shows how\n",
      "to build a recursive descent expression evaluator:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import collections\n",
      "\n",
      "# Token specification\n",
      "NUM = r'(?P<NUM>\\d+)'\n",
      "PLUS = r'(?P<PLUS>\\+)'\n",
      "MINUS = r'(?P<MINUS>-)'\n",
      "TIMES = r'(?P<TIMES>\\*)'\n",
      "DIVIDE = r'(?P<DIVIDE>/)'\n",
      "LPAREN = r'(?P<LPAREN>\\()'\n",
      "RPAREN = r'(?P<RPAREN>\\))'\n",
      "WS = r'(?P<WS>\\s+)'\n",
      "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,\n",
      "                        DIVIDE, LPAREN, RPAREN, WS]))\n",
      "\n",
      "# Tokenizer\n",
      "Token = collections.namedtuple('Token', ['type','value'])\n",
      "def generate_tokens(text):\n",
      "    scanner = master_pat.scanner(text)\n",
      "    for m in iter(scanner.match, None):\n",
      "        tok = Token(m.lastgroup, m.group())\n",
      "        if tok.type != 'WS':\n",
      "            yield tok\n",
      "\n",
      "# Parser\n",
      "class ExpressionEvaluator:\n",
      "    '''\n",
      "    Implementation of a recursive descent parser. Each method\n",
      "    implements a single grammar rule. Use the ._accept() method\n",
      "    to test and accept the current lookahead token. Use the ._expect()\n",
      "    method to exactly match and discard the next token on on the input\n",
      "    (or raise a SyntaxError if it doesn't match).\n",
      "    '''\n",
      "\n",
      "    def parse(self,text):\n",
      "        self.tokens = generate_tokens(text)\n",
      "        self.tok = None         # Last symbol consumed\n",
      "        self.nexttok = None     # Next symbol tokenized\n",
      "        self._advance()         # Load first lookahead token\n",
      "        return self.expr()\n",
      "\n",
      "    def _advance(self):\n",
      "        'Advance one token ahead'\n",
      "        self.tok, self.nexttok = self.nexttok, next(self.tokens, None)\n",
      "\n",
      "    def _accept(self,toktype):\n",
      "        'Test and consume the next token if it matches toktype'\n",
      "        if self.nexttok and self.nexttok.type == toktype:\n",
      "            self._advance()\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "\n",
      "    def _expect(self,toktype):\n",
      "        'Consume next token if it matches toktype or raise SyntaxError'\n",
      "        if not self._accept(toktype):\n",
      "            raise SyntaxError('Expected ' + toktype)\n",
      "    \n",
      "    # Grammar rules follow\n",
      "    \n",
      "    def expr(self):\n",
      "        \"expression ::= term { ('+'|'-') term }*\"\n",
      "    \n",
      "        exprval = self.term()\n",
      "        while self._accept('PLUS') or self._accept('MINUS'):\n",
      "            op = self.tok.type\n",
      "            right = self.term()\n",
      "            if op == 'PLUS':\n",
      "                exprval += right\n",
      "            elif op == 'MINUS':\n",
      "                exprval -= right\n",
      "        return exprval\n",
      "\n",
      "    def term(self):\n",
      "        \"term ::= factor { ('*'|'/') factor }*\"\n",
      "    \n",
      "        termval = self.factor()\n",
      "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
      "            op = self.tok.type\n",
      "            right = self.factor()\n",
      "            if op == 'TIMES':\n",
      "                termval *= right\n",
      "            elif op == 'DIVIDE':\n",
      "                termval /= right\n",
      "        return termval\n",
      "\n",
      "    def factor(self):\n",
      "        \"factor ::= NUM | ( expr )\"\n",
      "        if self._accept('NUM'):\n",
      "            return int(self.tok.value)\n",
      "        elif self._accept('LPAREN'):\n",
      "            exprval = self.expr()\n",
      "            self._expect('RPAREN')\n",
      "            return exprval\n",
      "        else:\n",
      "            raise SyntaxError('Expected NUMBER or LPAREN')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is an example of using the `ExpressionEvaluator` class interactively:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = ExpressionEvaluator()\n",
      "e.parse('2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.parse('2 + 3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "5"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.parse('2 + 3 * 4')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "14"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.parse('2 + (3 + 4) * 5')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "37"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.parse('2 + (3 + * 4)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "Expected NUMBER or LPAREN (<string>)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Expected NUMBER or LPAREN\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to do something other than pure evaluation, you need to change the\n",
      "`ExpressionEvaluator` class to do something else. For example, here is an alternative\n",
      "implementation that constructs a simple parse tree:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class ExpressionTreeBuilder(ExpressionEvaluator):\n",
      "    def expr(self):\n",
      "        \"expression ::= term { ('+'|'-') term }\"\n",
      "        \n",
      "        exprval = self.term()\n",
      "        while self._accept('PLUS') or self._accept('MINUS'):\n",
      "            op = self.tok.type\n",
      "            right = self.term()\n",
      "            if op == 'PLUS':\n",
      "                exprval = ('+', exprval, right)\n",
      "            elif op == 'MINUS':\n",
      "                exprval = ('-', exprval, right)\n",
      "        return exprval\n",
      "\n",
      "    def term(self):\n",
      "        \"term ::= factor { ('*'|'/') factor }\"\n",
      "        termval = self.factor()\n",
      "        while self._accept('TIMES') or self._accept('DIVIDE'):\n",
      "            op = self.tok.type\n",
      "            right = self.factor()\n",
      "            if op == 'TIMES':\n",
      "                termval = ('*', termval, right)\n",
      "            elif op == 'DIVIDE':\n",
      "                termval = ('/', termval, right)\n",
      "        return termval\n",
      "    \n",
      "    def factor(self):\n",
      "        'factor ::= NUM | ( expr )'\n",
      "        if self._accept('NUM'):\n",
      "            return int(self.tok.value)\n",
      "        elif self._accept('LPAREN'):\n",
      "            exprval = self.expr()\n",
      "            self._expect('RPAREN')\n",
      "            return exprval\n",
      "        else:\n",
      "            raise SyntaxError('Expected NUMBER or LPAREN')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following example shows how it works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = ExpressionTreeBuilder()\n",
      "e.parse('2 + 3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "('+', 2, 3)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.parse('2 + 3 * 4')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "('+', 2, ('*', 3, 4))"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.parse('2 + (3 + 4) * 5')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "('+', 2, ('*', ('+', 3, 4), 5))"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e.parse('2 + 3 + 4')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "('+', ('+', 2, 3), 4)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Discussion\n",
      "Parsing is a huge topic that generally occupies students for the first three weeks of a\n",
      "compilers course. If you are seeking background knowledge about grammars, parsing\n",
      "algorithms, and other information, a compilers book is where you should turn. Needless\n",
      "to say, all of that can\u2019t be repeated here.\n",
      "\n",
      "Nevertheless, the overall idea of writing a recursive descent parser is generally simple.\n",
      "To start, you take every grammar rule and you turn it into a function or method. Thus,\n",
      "if your grammar looks like this:\n",
      "```\n",
      "expr ::= term { ('+'|'-') term }*\n",
      "\n",
      "term ::= factor { ('*'|'/') factor }*\n",
      "\n",
      "factor ::= '(' expr ')'\n",
      "       | NUM\n",
      "```\n",
      "You start by turning it into a set of methods like this:\n",
      "```python\n",
      "class ExpressionEvaluator:\n",
      "    \u2026\n",
      "\n",
      "    def expr(self):\n",
      "        \u2026\n",
      "\n",
      "    def term(self):\n",
      "        \u2026\n",
      "\n",
      "    def factor(self):\n",
      "        \u2026\n",
      "```\n",
      "The task of each method is simple\u2014it must walk from left to right over each part of the\n",
      "grammar rule, consuming tokens in the process. In a sense, the goal of the method is\n",
      "to either consume the rule or generate a syntax error if it gets stuck. To do this, the\n",
      "following implementation techniques are applied:\n",
      "\n",
      "* If the next symbol in the rule is the name of another grammar rule (e.g., `term` or\n",
      "`factor`), you simply call the method with the same name. This is the \u201cdescent\u201d part\n",
      "of the algorithm\u2014control descends into another grammar rule. Sometimes rules\n",
      "will involve calls to methods that are already executing (e.g., the call to `expr` in the\n",
      "`factor ::= '(' expr ')'` rule). This is the \u201crecursive\u201d part of the algorithm.\n",
      "* If the next symbol in the rule has to be a specific symbol (e.g., `(`), you look at the\n",
      "next token and check for an exact match. If it doesn\u2019t match, it\u2019s a syntax error. The\n",
      "`_expect()` method in this recipe is used to perform these steps.\n",
      "* If the next symbol in the rule could be a few possible choices (e.g., `+` or `-`), you have\n",
      "to check the next token for each possibility and advance only if a match is made.\n",
      "This is the purpose of the `_accept()` method in this recipe. It\u2019s kind of like a weaker\n",
      "version of the `_expect()` method in that it will advance if a match is made, but if\n",
      "not, it simply backs off without raising an error (thus allowing further checks to be\n",
      "made).\n",
      "* For grammar rules where there are repeated parts (e.g., such as in the rule \n",
      "`expr ::= term { ('+'|'-') term }*`), the repetition gets implemented by a `while` loop.\n",
      "The body of the loop will generally collect or process all of the repeated items until\n",
      "no more are found.\n",
      "\u2022 Once an entire grammar rule has been consumed, each method returns some kind\n",
      "of result back to the caller. This is how values propagate during parsing. For ex\u2010\n",
      "ample, in the expression evaluator, return values will represent partial results of the\n",
      "expression being parsed. Eventually they all get combined together in the topmost\n",
      "grammar rule method that executes.\n",
      "\n",
      "Although a simple example has been shown, recursive descent parsers can be used to\n",
      "implement rather complicated parsers. For example, Python code itself is interpreted\n",
      "by a recursive descent parser. If you\u2019re so inclined, you can look at the underlying gram\u2010\n",
      "mar by inspecting the file _Grammar_/_Grammar_ in the Python source. That said, there\n",
      "are still numerous pitfalls and limitations with making a parser by hand.\n",
      "\n",
      "One such limitation of recursive descent parsers is that they can\u2019t be written for grammar\n",
      "rules involving any kind of left recursion. For example, suppose you need to translate a\n",
      "rule like this:\n",
      "```\n",
      "items ::= items ',' item\n",
      "      | item\n",
      "```\n",
      "\n",
      "To do it, you might try to use the `items()` method like this:\n",
      "```python\n",
      "def items(self):\n",
      "    itemsval = self.items()\n",
      "    if itemsval and self._accept(','):\n",
      "        itemsval.append(self.item())\n",
      "    else:\n",
      "        itemsval = [self.item()]\n",
      "```\n",
      "The only problem is that it doesn\u2019t work. In fact, it blows up with an infinite recursion\n",
      "error.\n",
      "\n",
      "You can also run into tricky issues concerning the grammar rules themselves. For ex\u2010\n",
      "ample, you might have wondered whether or not expressions could have been described\n",
      "by this more simple grammar:\n",
      "```\n",
      "expr ::= factor { ('+'|'-'|'*'|'/') factor }*\n",
      "factor ::= '(' expression ')'\n",
      "       | NUM\n",
      "```\n",
      "\n",
      "This grammar technically \u201cworks,\u201d but it doesn\u2019t observe the standard arithmetic rules\n",
      "concerning order of evaluation. For example, the expression \u201c3 + 4 * 5\u201d would get eval\u2010\n",
      "uated as \u201c35\u201d instead of the expected result of \u201c23.\u201d The use of separate \u201cexpr\u201d and \u201cterm\u201d\n",
      "rules is there to make evaluation work correctly.\n",
      "\n",
      "For really complicated grammars, you are often better off using parsing tools such as\n",
      "PyParsing or PLY. This is what the expression evaluator code looks like using PLY:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ply.lex import lex\n",
      "from ply.yacc import yacc\n",
      "\n",
      "# Token list\n",
      "tokens = [ 'NUM', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN' ]\n",
      "\n",
      "# Ignored characters\n",
      "t_ignore = ' \\t\\n'\n",
      "\n",
      "# Token specifications (as regexs)\n",
      "t_PLUS = r'\\+'\n",
      "t_MINUS = r'-'\n",
      "t_TIMES = r'\\*'\n",
      "t_DIVIDE = r'/'\n",
      "t_LPAREN = r'\\('\n",
      "t_RPAREN = r'\\)'\n",
      "\n",
      "# Token processing functions\n",
      "def t_NUM(t):\n",
      "    r'\\d+'\n",
      "    t.value = int(t.value)\n",
      "    return t\n",
      "\n",
      "# Error handler\n",
      "def t_error(t):\n",
      "    print('Bad character: {!r}'.format(t.value[0]))\n",
      "    t.skip(1)\n",
      "\n",
      "# Build the lexer\n",
      "lexer = lex()\n",
      "\n",
      "# Grammar rules and handler functions\n",
      "def p_expr(p):\n",
      "    '''\n",
      "    expr : expr PLUS term\n",
      "         | expr MINUS term\n",
      "    '''\n",
      "    if p[2] == '+':\n",
      "        p[0] = p[1] + p[3]\n",
      "    elif p[2] == '-':\n",
      "        p[0] = p[1] - p[3]\n",
      "\n",
      "def p_expr_term(p):\n",
      "    '''\n",
      "    expr : term\n",
      "    '''\n",
      "    p[0] = p[1]\n",
      "\n",
      "def p_term(p):\n",
      "    '''\n",
      "    term : term TIMES factor\n",
      "        | term DIVIDE factor\n",
      "    '''\n",
      "    if p[2] == '*':\n",
      "        p[0] = p[1] * p[3]\n",
      "    elif p[2] == '/':\n",
      "        p[0] = p[1] / p[3]\n",
      "\n",
      "def p_term_factor(p):\n",
      "    '''\n",
      "    term : factor\n",
      "    '''\n",
      "    p[0] = p[1]\n",
      "\n",
      "def p_factor(p):\n",
      "    '''\n",
      "    factor : NUM\n",
      "    '''\n",
      "    p[0] = p[1]\n",
      "\n",
      "def p_factor_group(p):\n",
      "    '''\n",
      "    factor : LPAREN expr RPAREN\n",
      "    '''\n",
      "    p[0] = p[2]\n",
      "\n",
      "def p_error(p):\n",
      "    print('Syntax error')\n",
      "\n",
      "parser = yacc()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this code, you\u2019ll find that everything is specified at a much higher level. You simply\n",
      "write regular expressions for the tokens and high-level handling functions that execute\n",
      "when various grammar rules are matched. The actual mechanics of running the parser,\n",
      "accepting tokens, and so forth is implemented entirely by the library.\n",
      "\n",
      "Here is an example of how the resulting parser object gets used:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parser.parse('2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parser.parse('2+3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "5"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parser.parse('2+(3+4)*5')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "37"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you need a bit more excitement in your programming, writing parsers and compilers\n",
      "can be a fun project. Again, a compilers textbook will have a lot of low-level details\n",
      "underlying theory. However, many fine resources can also be found online. Python\u2019s\n",
      "own `ast` module is also worth a look."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}